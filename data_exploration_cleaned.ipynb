{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a160f2c-4fa3-4a4c-b47c-660c3edf2e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import wfdb\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ee309-4a3f-4f19-a0ad-48a5f1517265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "# Since audio data, need signed bit integer\n",
    "# According to dataset: 32-bit\n",
    "SIGNED_32BIT = 2**31 - 1\n",
    "\n",
    "# According to dataset: 8000Hz\n",
    "SAMPLING_FREQ = 8000\n",
    "\n",
    "# Since 32-bit, 8bits/byte\n",
    "SAMPLE_WIDTH = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17681c6c-45bc-4077-9698-58acdc9ef7d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba794d-eb9a-4ded-9704-5981717d1d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw dataset file path\n",
    "rawdata_path = \"resources/voiced_dataset/\"\n",
    "\n",
    "# Get all the files in the directory\n",
    "files = os.listdir(rawdata_path)\n",
    "\n",
    "# Create lists to check dataset\n",
    "voice_info = []\n",
    "voice_file = []\n",
    "audio_file = []\n",
    "\n",
    "# Loop through each file\n",
    "for file in files:\n",
    "    \n",
    "    # Look through voice files only\n",
    "    if file.startswith(\"voice\"):\n",
    "        \n",
    "        # Isolate the info text files\n",
    "        if file.endswith(\"-info.txt\"):\n",
    "            voice_id = file.split(\"-\")[0]\n",
    "            voice_info.append(voice_id)\n",
    "        \n",
    "        # Isolate the voice text files\n",
    "        elif file.endswith(\".txt\"):\n",
    "            voice_id = file.split(\".\")[0]\n",
    "            voice_file.append(voice_id)\n",
    "            \n",
    "        # Isolate the audio files\n",
    "        elif file.endswith(\".hea\"):\n",
    "            voice_id = file.split(\".\")[0]\n",
    "            audio_file.append(voice_id)\n",
    "\n",
    "# Confirm each sample has a signal and info file\n",
    "print(f'Info file: {len(set(voice_info))}')\n",
    "print(f'Signal file: {len(set(voice_file))}')\n",
    "print(f'Audio file: {len(set(audio_file))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4ea184-48ba-45a7-ad36-24495e4b3256",
   "metadata": {},
   "source": [
    "### Convert wfdb to wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdeec3f-dcfd-455f-8689-81e1c27044b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a wav file\n",
    "for file in files:\n",
    "    \n",
    "    # Extract .hea files only\n",
    "    if file.startswith(\"voice\") and file.endswith(\".hea\"):\n",
    "        voice_id = file.split(\".\")[0]\n",
    "        \n",
    "        # Get the record name\n",
    "        record_name = rawdata_path + voice_id\n",
    "        \n",
    "        # Read the wfdb record\n",
    "        record = wfdb.rdrecord(record_name)\n",
    "        \n",
    "        # Get the signal data and sampling freq (fs)\n",
    "        signal_data = record.p_signal\n",
    "        fs = record.fs\n",
    "        \n",
    "        # Find the min and max of the signal data\n",
    "        signal_min = np.min(signal_data)\n",
    "        signal_max = np.max(signal_data)\n",
    "        \n",
    "        # Normalise and scale to 32-bit range\n",
    "        normalised_signal = (signal_data - signal_min) / (signal_max - signal_min)\n",
    "        normalised_signal = (SIGNED_32BIT * normalised_signal).astype(np.int32)\n",
    "        \n",
    "        # Create an AudioSegment from the normalised signal data\n",
    "        audio_segment = AudioSegment(\n",
    "            normalised_signal.tobytes(),\n",
    "            frame_rate = fs,\n",
    "            sample_width = SAMPLE_WIDTH,\n",
    "            channels = 1 # mono, not stereo\n",
    "        )\n",
    "        \n",
    "        # Save as a wav file\n",
    "        output_filename = f'resources/audio_files/{voice_id}.wav'\n",
    "        audio_segment.export(output_filename, format='wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7370f4f8-5418-40ef-afc4-0ca4d62aee48",
   "metadata": {},
   "source": [
    "### Convert info text file to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67263ace-1a81-432f-b19e-eac8db182527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an example of the info text file\n",
    "sample_file = rawdata_path + \"voice001-info.txt\"\n",
    "\n",
    "# Read the text file\n",
    "with open(sample_file, 'r') as file:\n",
    "    for line in file:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613bf4d-4482-448c-84a9-424ff79adcf2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialise the list to hold dictionaries\n",
    "metadata_list = []\n",
    "\n",
    "# Parse the data in the info files\n",
    "for file in files:\n",
    "    \n",
    "    # Initialise the dictionary to store the info\n",
    "    metadata_dict = dict()\n",
    "    \n",
    "    # Look through info files only\n",
    "    if file.startswith(\"voice\") and file.endswith(\"-info.txt\"):\n",
    "        \n",
    "        # Read the text file\n",
    "        with open(rawdata_path + file, 'r') as file:\n",
    "            for line in file:\n",
    "                \n",
    "                # Split each line into a key-value pair using delimiter\n",
    "                key, value = map(str.strip, line.split(\"\\t\"))\n",
    "                \n",
    "                # Ignore the empty lines by checking whitespaces\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                else:\n",
    "                    # Remove the colon\n",
    "                    key = key.replace(\":\", \"\")\n",
    "                    \n",
    "                    # Load the data to a dictionary\n",
    "                    metadata_dict[key] = value\n",
    "                    \n",
    "            # Append the dictionary to the list\n",
    "            metadata_list.append(metadata_dict)\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "metadata_df = pd.DataFrame(metadata_list)\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d64e07-6016-43b7-969e-bfea0fd6e72f",
   "metadata": {},
   "source": [
    "### Signal Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3711d0f-f9a4-41fe-a126-c77e59b4125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the audio files\n",
    "audio_path = \"resources/audio_files/\"\n",
    "audio_files = os.listdir(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3a655-7019-459b-a324-7275891e6611",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the first 3 waveforms\n",
    "for file in audio_files[:3]:\n",
    "    \n",
    "    # Load the file\n",
    "    y, sr = librosa.load(\n",
    "        audio_path + file, # full file path\n",
    "        sr = None # preserve sampling rate\n",
    "    )\n",
    "    \n",
    "    # Plot the waveform\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    \n",
    "    # Add labels\n",
    "    plt.title(f'Waveform [{file.split(\".\")[0]}]')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    \n",
    "    # Display the waveform\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a854d-78b6-44fc-8b05-edbad1f6afd2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the first 3 spectrograms\n",
    "for file in audio_files[:3]:\n",
    "    \n",
    "    # Load the file\n",
    "    y, sr = librosa.load(\n",
    "        audio_path + file, # full file path\n",
    "        sr = None # preserve sampling rate\n",
    "    )\n",
    "    \n",
    "    # Plot the spectrogram\n",
    "    D = librosa.amplitude_to_db(\n",
    "        np.abs(librosa.stft(y)),\n",
    "        ref = np.max\n",
    "    )\n",
    "\n",
    "    # Plot the spectrogram\n",
    "    librosa.display.specshow(\n",
    "        D,\n",
    "        sr = sr,\n",
    "        x_axis='time',\n",
    "        y_axis='log' # can also choose: linear\n",
    "    )\n",
    "    \n",
    "    # Add labels\n",
    "    plt.title(f'Waveform [{file.split(\".\")[0]}]')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998b31d7-3255-4f37-bc9f-0e08e72745b8",
   "metadata": {},
   "source": [
    "## Formants using Parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c137e8b-33fe-428b-9226-2ded6eba9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in audio_files[:3]:\n",
    "    \n",
    "    # Load the audio file\n",
    "    sound = parselmouth.Sound(audio_path + file)\n",
    "    \n",
    "    # Extract the formants - Burg's method\n",
    "    formants = sound.to_formant_burg()\n",
    "    print(formants)\n",
    "    \n",
    "    # Define fundamental freq limits\n",
    "    f0_min = 50\n",
    "    f0_max = SAMPLING_FREQ / 2 # Nyquist frequency\n",
    "    \n",
    "    # Compute the occurrences of periodic instances\n",
    "    pointProcess = parselmouth.praat.call(\n",
    "        sound,\n",
    "        \"To PointProcess (periodic, cc)\",\n",
    "        f0_min,\n",
    "        f0_max\n",
    "    )\n",
    "    \n",
    "    # Compute the formants\n",
    "    formants = parselmouth.praat.call(\n",
    "        sound,\n",
    "        \"To Formant (burg)\",\n",
    "        0.0025,\n",
    "        5,\n",
    "        5000,\n",
    "        0.025,\n",
    "        50\n",
    "    )\n",
    "    \n",
    "    numPoints = parselmouth.praat.call(pointProcess, \"Get number of points\")\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = parselmouth.praat.call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = parselmouth.praat.call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = parselmouth.praat.call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = parselmouth.praat.call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        \n",
    "    print(len(f1_list), len(f2_list), len(f3_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a39ddfd-4105-40db-8db8-f6ea8030d652",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Harmonics using Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656ac24-ddcc-4689-88a0-519d353286c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the fundamental frequency (f0)\n",
    "for file in audio_files[:4]:\n",
    "    print(file)\n",
    "    \n",
    "    # Load the file\n",
    "    y, sr = librosa.load(\n",
    "        audio_path + file, # full file path\n",
    "        sr = None # preserve sampling rate\n",
    "    )\n",
    "\n",
    "    # Estimate f0\n",
    "    f0, voicing, voicing_probability = librosa.pyin(\n",
    "        y = y,\n",
    "        sr = sr,\n",
    "        fmin = 50,\n",
    "        fmax = sr / 2 # Nyquist frequency\n",
    "    )\n",
    "    \n",
    "    # Magnitude spectrogram - freq content of signal over time\n",
    "    S = np.abs(librosa.stft(y))\n",
    "    \n",
    "    # Get the frequency bins\n",
    "    freqs = librosa.fft_frequencies(sr=sr)\n",
    "    print(len(freqs), freqs)\n",
    "    \n",
    "    # Harmonic analysis (first 12)\n",
    "    harmonics = np.arange(1, 13)\n",
    "    f0_harmonics = librosa.f0_harmonics(\n",
    "        S,\n",
    "        freqs = freqs,\n",
    "        f0 = f0,\n",
    "        harmonics = harmonics\n",
    "    )\n",
    "    print(len(f0_harmonics), len(f0_harmonics[0]))\n",
    "    \n",
    "    fig, ax =plt.subplots(nrows=2, sharex=True)\n",
    "    librosa.display.specshow(\n",
    "        librosa.amplitude_to_db(S, ref=np.max),\n",
    "        x_axis='time',\n",
    "        y_axis='log',\n",
    "        ax=ax[0]\n",
    "    )\n",
    "    times = librosa.times_like(f0)\n",
    "    for h in harmonics:\n",
    "        ax[0].plot(times, h * f0, label=f\"{h}*f0\")\n",
    "    ax[0].legend(ncols=4, loc='lower right')\n",
    "    ax[0].label_outer()\n",
    "\n",
    "    librosa.display.specshow(\n",
    "        librosa.amplitude_to_db(f0_harmonics, ref=np.max),\n",
    "        x_axis = 'time',\n",
    "        ax = ax[1]\n",
    "    )\n",
    "    ax[1].set_yticks(harmonics-1)\n",
    "    ax[1].set_yticklabels(harmonics)\n",
    "    ax[1].set(ylabel='Harmonics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577660b8-66ee-4ab0-b005-07d71f818e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.loc[metadata_df['ID'].isin(['voice094', 'voice080', 'voice057', 'voice043'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc0e87-2ef8-44b9-aa2c-99dfd3a397f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in audio_files[:3]:\n",
    "    \n",
    "    # Load the file\n",
    "    y, sr = librosa.load(\n",
    "        audio_path + file, # full file path\n",
    "        sr = None # preserve sampling rate\n",
    "    )\n",
    "\n",
    "    # Extract harmonics\n",
    "    harmonic, percussive = librosa.effects.hpss(y)\n",
    "    # print(len(harmonic), harmonic)\n",
    "    \n",
    "    # Extract pitches\n",
    "    # pitches, magnitudes = librosa.core.piptrack(\n",
    "    #     y = harmonic,\n",
    "    #     sr = sr\n",
    "    # )\n",
    "    \n",
    "    # Get the indices\n",
    "    hps = librosa.effects.harmonic(y)\n",
    "    print(len(hps), hps)\n",
    "    print(len(harmonic), harmonic)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Create the time axis\n",
    "    # time = np.arange(0, len(y)) / sr\n",
    "    \n",
    "    # Plot the original waveform and harmonics\n",
    "    # plt.plot(time, y, label = 'Original Signal')\n",
    "    # plt.plot(\n",
    "    #     time,\n",
    "    #     harmonic,\n",
    "    #     label = 'Harmonic Component',\n",
    "    #     linestyle = '--'\n",
    "    # )\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8110b04-2049-456b-9ac3-dde58f74c3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13aacf-7e72-460f-82f9-312a79ba990a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
