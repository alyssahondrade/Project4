{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0315dbc-359f-46ef-bb03-5c55ad8f7d89",
   "metadata": {},
   "source": [
    "# Spectrograms - CNN Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef9fa8e4-1d6e-4d44-985e-2bb2f74edb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from pprint import pprint\n",
    "\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "%run functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27da9635-2bec-410d-ae28-056be6bfcca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time the run\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a61a686-d623-4f56-b457-b05d07f8a1fc",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280d822a-ec18-4e46-a284-3fd9a0953c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aval',\n",
       " 'bval',\n",
       " 'demographic',\n",
       " 'diagnosis',\n",
       " 'gval',\n",
       " 'habits',\n",
       " 'rval',\n",
       " 'spectrogram']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "engine = create_engine(\"sqlite:///voice.sqlite\")\n",
    "\n",
    "# View all of the classes\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b42f04-e984-4db5-a4d1-53ad7c4e1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a dictionary to hold dataframes\n",
    "dataframes = dict()\n",
    "\n",
    "# Loop through each table\n",
    "for table in table_names:\n",
    "    \n",
    "    # Dataframe name\n",
    "    df_name = f'{table}_df'\n",
    "    \n",
    "    # Create dataframe\n",
    "    dataframes[df_name] = pd.read_sql(\n",
    "        f'SELECT * FROM {table}',\n",
    "        engine\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b987cb55-0b86-48cf-b436-b5624577f1ed",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075473b9-9750-459c-be18-97755fc5637f",
   "metadata": {},
   "source": [
    "### Define the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3f842a-e9c2-4ca4-ad15-3d8bb4837157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "199    0\n",
       "200    1\n",
       "201    1\n",
       "202    0\n",
       "203    0\n",
       "Name: diagnosis, Length: 204, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate the diagnosis column\n",
    "y = dataframes['diagnosis_df']['diagnosis'].copy()\n",
    "\n",
    "# Encode the target variable, ignore subtype\n",
    "y = y.apply(encode_binary)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d9885-6a93-4229-b3ce-03b172e62e0b",
   "metadata": {},
   "source": [
    "### Reshape the feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2061a3aa-5b45-4f07-bf6d-e1264a8d68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape\n",
    "width_px = 225\n",
    "height_px = 166\n",
    "num_channels = 4 # since RGBA\n",
    "\n",
    "# Define inputs\n",
    "input_shape = (height_px, width_px, num_channels)\n",
    "input_reshape = (height_px, width_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd6eb688-b89c-4614-8bb6-a395546cd8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 47,  17,  99, 255],\n",
       "        [ 47,  17,  99, 255],\n",
       "        [ 43,  16,  93, 255],\n",
       "        ...,\n",
       "        [ 35,  11,  70, 255],\n",
       "        [ 47,  16,  90, 255],\n",
       "        [ 49,  17,  93, 255]],\n",
       "\n",
       "       [[ 45,  17,  97, 255],\n",
       "        [ 45,  17,  98, 255],\n",
       "        [ 41,  16,  90, 255],\n",
       "        ...,\n",
       "        [ 49,  15,  93, 255],\n",
       "        [ 59,  16, 108, 255],\n",
       "        [ 60,  15, 111, 255]],\n",
       "\n",
       "       [[ 46,  17,  98, 255],\n",
       "        [ 46,  17,  99, 255],\n",
       "        [ 43,  16,  92, 255],\n",
       "        ...,\n",
       "        [ 29,  13,  68, 255],\n",
       "        [ 51,  16,  99, 255],\n",
       "        [ 54,  16, 104, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[215,  69, 107, 255],\n",
       "        [215,  69, 107, 255],\n",
       "        [211,  67, 109, 255],\n",
       "        ...,\n",
       "        [ 76,  18, 120, 255],\n",
       "        [184,  56, 115, 255],\n",
       "        [201,  62, 114, 255]],\n",
       "\n",
       "       [[235,  90,  96, 255],\n",
       "        [235,  90,  96, 255],\n",
       "        [231,  87,  98, 255],\n",
       "        ...,\n",
       "        [ 91,  20, 125, 255],\n",
       "        [206,  70, 105, 255],\n",
       "        [225,  77, 101, 255]],\n",
       "\n",
       "       [[250, 158, 116, 255],\n",
       "        [250, 158, 116, 255],\n",
       "        [249, 157, 116, 255],\n",
       "        ...,\n",
       "        [162, 103, 138, 255],\n",
       "        [236, 150, 123, 255],\n",
       "        [248, 157, 120, 255]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe order\n",
    "rgba_order = ['rval_df', 'gval_df', 'bval_df', 'aval_df']\n",
    "\n",
    "# Initialise list to hold the dataframes\n",
    "rgba_df_list = []\n",
    "\n",
    "# Loop through all the dataframes\n",
    "for df in rgba_order:\n",
    "    \n",
    "    # Define the df columns\n",
    "    df_cols = dataframes[df].columns\n",
    "\n",
    "    # Reshape to its original dimensions\n",
    "    data = np.array(\n",
    "        [dataframes[df][col].values.reshape(input_reshape) for col in df_cols]\n",
    "    )\n",
    "\n",
    "    # Append to the list\n",
    "    rgba_df_list.append(data)\n",
    "\n",
    "# Define the feature variables\n",
    "X = np.stack(rgba_df_list, axis=-1)\n",
    "\n",
    "# Display the first for confirmation\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f9776-eac2-4eaa-a8d4-fb862aea67d0",
   "metadata": {},
   "source": [
    "### Split and Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93026db2-4f60-426a-9be9-89c669c30b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data to training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e818da95-d81e-4df7-b4aa-6c8e8f3896e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "X_train_reshaped = X_train.reshape((\n",
    "    X_train.shape[0], # total number of samples\n",
    "    height_px * width_px * num_channels # total number flattened\n",
    "))\n",
    "\n",
    "X_test_reshaped = X_test.reshape((\n",
    "    X_test.shape[0],\n",
    "    height_px * width_px * num_channels\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe9751b7-f7c9-4071-8745-dc39a000f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize training data to be between 0 and 1\n",
    "X_scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.fit_transform(X_train_reshaped)\n",
    "X_test_scaled = X_scaler.fit_transform(X_test_reshaped)\n",
    "\n",
    "# Reshape the data back to the original\n",
    "X_train_scaled = X_train_scaled.reshape((\n",
    "    X_train_scaled.shape[0],\n",
    "    height_px,\n",
    "    width_px,\n",
    "    num_channels\n",
    "))\n",
    "\n",
    "X_test_scaled = X_test_scaled.reshape((\n",
    "    X_test_scaled.shape[0],\n",
    "    height_px,\n",
    "    width_px,\n",
    "    num_channels\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3348655-306e-4f98-8309-b8b7a3eb6aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 164, 223, 32)      1184      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 82, 111, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 80, 109, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 40, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 38, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 19, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 63232)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               8093824   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8187489 (31.23 MB)\n",
      "Trainable params: 8187489 (31.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "cnn = Sequential()\n",
    "\n",
    "# Add first convolutional layer\n",
    "cnn.add(Conv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = (3, 3),\n",
    "    activation = 'relu',\n",
    "    input_shape = (height_px, width_px, num_channels)\n",
    "))\n",
    "\n",
    "# Add first pooling layer\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add second convolutional layer\n",
    "cnn.add(Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = (3, 3),\n",
    "    activation = 'relu'\n",
    "))\n",
    "\n",
    "# Add second pooling layer\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add third convolutional layer\n",
    "cnn.add(Conv2D(\n",
    "    filters = 128,\n",
    "    kernel_size = (3, 3),\n",
    "    activation = 'relu'\n",
    "))\n",
    "\n",
    "# Add third pooling layer\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output before feeding into the fully connected layers\n",
    "cnn.add(Flatten())\n",
    "\n",
    "# Add dense layers for classification\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "cnn.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "\n",
    "# Display the summary\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d3b9fb1-bbc1-444b-8c6f-67e50f2176c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "cnn.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46a90f68-bf6a-45d9-9b02-e83c4bdbf346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 1.2194 - accuracy: 0.5490\n",
      "Epoch 2/15\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.6024 - accuracy: 0.7190\n",
      "Epoch 3/15\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.5809 - accuracy: 0.7190\n",
      "Epoch 4/15\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.6609 - accuracy: 0.7190\n",
      "Epoch 5/15\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.6266 - accuracy: 0.7190\n",
      "Epoch 6/15\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.5693 - accuracy: 0.7190\n",
      "Epoch 7/15\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.5589 - accuracy: 0.7190\n",
      "Epoch 8/15\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.5334 - accuracy: 0.7255\n",
      "Epoch 9/15\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.5068 - accuracy: 0.7255\n",
      "Epoch 10/15\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.4706 - accuracy: 0.7908\n",
      "Epoch 11/15\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.4094 - accuracy: 0.8235\n",
      "Epoch 12/15\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.4355 - accuracy: 0.7908\n",
      "Epoch 13/15\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.3378 - accuracy: 0.8562\n",
      "Epoch 14/15\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.2572 - accuracy: 0.8824\n",
      "Epoch 15/15\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.2083 - accuracy: 0.9281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a96b5390>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "cnn.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs = 15,\n",
    "    shuffle = True, # reduce risk of overfitting\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cbff7c9-8aad-4bff-b2e0-dd36b6f608f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 0.7912 - accuracy: 0.7255 - 141ms/epoch - 70ms/step\n",
      "Loss: 0.791204571723938, Accuracy: 0.7254902124404907\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = cnn.evaluate(\n",
    "    X_test_scaled,\n",
    "    y_test,\n",
    "    verbose = 2\n",
    ")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10494d54-3d2c-487a-9d8e-5f454a6a5d92",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5227b15-08ae-4b2e-850d-2ca05755fbc8",
   "metadata": {},
   "source": [
    "__GUIDELINES__\n",
    "\n",
    "- The number of filters for convolutional layers should:\n",
    "    - Be a value to the power of 2\n",
    "    - Increase for each following layer (i.e. `32`, `64`, `128`)\n",
    "- The number of neurons for the fully connected layers should:\n",
    "    - Be a value to the power of 2\n",
    "    - Decrease for each following layer (i.e. `64`, `32`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a6e5d-c6dd-48d6-90f6-3e94e302dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed50fdc-1648-481f-bea9-4894bbc2cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(hp):\n",
    "    cnn_model = Sequential()\n",
    "\n",
    "    # Choose the number of convolutional layers\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
