{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0315dbc-359f-46ef-bb03-5c55ad8f7d89",
   "metadata": {},
   "source": [
    "# Spectrograms - CNN Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef9fa8e4-1d6e-4d44-985e-2bb2f74edb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from pprint import pprint\n",
    "\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "%run functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27da9635-2bec-410d-ae28-056be6bfcca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time the run\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a61a686-d623-4f56-b457-b05d07f8a1fc",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280d822a-ec18-4e46-a284-3fd9a0953c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aval',\n",
       " 'bval',\n",
       " 'chroma1',\n",
       " 'chroma10',\n",
       " 'chroma11',\n",
       " 'chroma12',\n",
       " 'chroma2',\n",
       " 'chroma3',\n",
       " 'chroma4',\n",
       " 'chroma5',\n",
       " 'chroma6',\n",
       " 'chroma7',\n",
       " 'chroma8',\n",
       " 'chroma9',\n",
       " 'chromastd',\n",
       " 'delta',\n",
       " 'demographic',\n",
       " 'diagnosis',\n",
       " 'energy',\n",
       " 'energyentropy',\n",
       " 'gval',\n",
       " 'habits',\n",
       " 'mfcc1',\n",
       " 'mfcc10',\n",
       " 'mfcc11',\n",
       " 'mfcc12',\n",
       " 'mfcc13',\n",
       " 'mfcc2',\n",
       " 'mfcc3',\n",
       " 'mfcc4',\n",
       " 'mfcc5',\n",
       " 'mfcc6',\n",
       " 'mfcc7',\n",
       " 'mfcc8',\n",
       " 'mfcc9',\n",
       " 'rval',\n",
       " 'spectralcentroid',\n",
       " 'spectralentropy',\n",
       " 'spectralflux',\n",
       " 'spectralrolloff',\n",
       " 'spectralspread',\n",
       " 'zcr']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "engine = create_engine(\"sqlite:///voice.sqlite\")\n",
    "\n",
    "# View all of the classes\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b42f04-e984-4db5-a4d1-53ad7c4e1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a dictionary to hold dataframes\n",
    "dataframes = dict()\n",
    "\n",
    "# Loop through each table\n",
    "for table in table_names:\n",
    "    \n",
    "    # Dataframe name\n",
    "    df_name = f'{table}_df'\n",
    "    \n",
    "    # Create dataframe\n",
    "    dataframes[df_name] = pd.read_sql(\n",
    "        f'SELECT * FROM {table}',\n",
    "        engine\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b987cb55-0b86-48cf-b436-b5624577f1ed",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075473b9-9750-459c-be18-97755fc5637f",
   "metadata": {},
   "source": [
    "### Define the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3f842a-e9c2-4ca4-ad15-3d8bb4837157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "199    0\n",
       "200    1\n",
       "201    1\n",
       "202    0\n",
       "203    0\n",
       "Name: diagnosis, Length: 204, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate the diagnosis column\n",
    "y = dataframes['diagnosis_df']['diagnosis'].copy()\n",
    "\n",
    "# Encode the target variable, ignore subtype\n",
    "y = y.apply(encode_binary)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d9885-6a93-4229-b3ce-03b172e62e0b",
   "metadata": {},
   "source": [
    "### Reshape the feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2061a3aa-5b45-4f07-bf6d-e1264a8d68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape\n",
    "width_px = 225\n",
    "height_px = 166\n",
    "num_channels = 4 # since RGBA\n",
    "\n",
    "# Define inputs\n",
    "input_shape = (height_px, width_px, num_channels)\n",
    "input_reshape = (height_px, width_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd6eb688-b89c-4614-8bb6-a395546cd8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 47,  17,  99, 255],\n",
       "        [ 47,  17,  99, 255],\n",
       "        [ 43,  16,  93, 255],\n",
       "        ...,\n",
       "        [ 35,  11,  70, 255],\n",
       "        [ 47,  16,  90, 255],\n",
       "        [ 49,  17,  93, 255]],\n",
       "\n",
       "       [[ 45,  17,  97, 255],\n",
       "        [ 45,  17,  98, 255],\n",
       "        [ 41,  16,  90, 255],\n",
       "        ...,\n",
       "        [ 49,  15,  93, 255],\n",
       "        [ 59,  16, 108, 255],\n",
       "        [ 60,  15, 111, 255]],\n",
       "\n",
       "       [[ 46,  17,  98, 255],\n",
       "        [ 46,  17,  99, 255],\n",
       "        [ 43,  16,  92, 255],\n",
       "        ...,\n",
       "        [ 29,  13,  68, 255],\n",
       "        [ 51,  16,  99, 255],\n",
       "        [ 54,  16, 104, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[215,  69, 107, 255],\n",
       "        [215,  69, 107, 255],\n",
       "        [211,  67, 109, 255],\n",
       "        ...,\n",
       "        [ 76,  18, 120, 255],\n",
       "        [184,  56, 115, 255],\n",
       "        [201,  62, 114, 255]],\n",
       "\n",
       "       [[235,  90,  96, 255],\n",
       "        [235,  90,  96, 255],\n",
       "        [231,  87,  98, 255],\n",
       "        ...,\n",
       "        [ 91,  20, 125, 255],\n",
       "        [206,  70, 105, 255],\n",
       "        [225,  77, 101, 255]],\n",
       "\n",
       "       [[250, 158, 116, 255],\n",
       "        [250, 158, 116, 255],\n",
       "        [249, 157, 116, 255],\n",
       "        ...,\n",
       "        [162, 103, 138, 255],\n",
       "        [236, 150, 123, 255],\n",
       "        [248, 157, 120, 255]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe order\n",
    "rgba_order = ['rval_df', 'gval_df', 'bval_df', 'aval_df']\n",
    "\n",
    "# Initialise list to hold the dataframes\n",
    "rgba_df_list = []\n",
    "\n",
    "# Loop through all the dataframes\n",
    "for df in rgba_order:\n",
    "    \n",
    "    # Define the df columns\n",
    "    df_cols = dataframes[df].columns\n",
    "\n",
    "    # Reshape to its original dimensions\n",
    "    data = np.array(\n",
    "        [dataframes[df][col].values.reshape(input_reshape) for col in df_cols]\n",
    "    )\n",
    "\n",
    "    # Append to the list\n",
    "    rgba_df_list.append(data)\n",
    "\n",
    "# Define the feature variables\n",
    "X = np.stack(rgba_df_list, axis=-1)\n",
    "\n",
    "# Display the first for confirmation\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f9776-eac2-4eaa-a8d4-fb862aea67d0",
   "metadata": {},
   "source": [
    "### Split and Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93026db2-4f60-426a-9be9-89c669c30b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data to training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e818da95-d81e-4df7-b4aa-6c8e8f3896e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "X_train_reshaped = X_train.reshape((\n",
    "    X_train.shape[0], # total number of samples\n",
    "    height_px * width_px * num_channels # total number flattened\n",
    "))\n",
    "\n",
    "X_test_reshaped = X_test.reshape((\n",
    "    X_test.shape[0],\n",
    "    height_px * width_px * num_channels\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe9751b7-f7c9-4071-8745-dc39a000f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize training data to be between 0 and 1\n",
    "X_scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.fit_transform(X_train_reshaped)\n",
    "X_test_scaled = X_scaler.fit_transform(X_test_reshaped)\n",
    "\n",
    "# Reshape the data back to the original\n",
    "X_train_scaled = X_train_scaled.reshape((\n",
    "    X_train_scaled.shape[0],\n",
    "    height_px,\n",
    "    width_px,\n",
    "    num_channels\n",
    "))\n",
    "\n",
    "X_test_scaled = X_test_scaled.reshape((\n",
    "    X_test_scaled.shape[0],\n",
    "    height_px,\n",
    "    width_px,\n",
    "    num_channels\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543476ca-4a81-48bd-8b2b-91851f9b2811",
   "metadata": {},
   "source": [
    "## Initial Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3348655-306e-4f98-8309-b8b7a3eb6aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 164, 223, 32)      1184      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 82, 111, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 80, 109, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 40, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 38, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 19, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 63232)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               8093824   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8187489 (31.23 MB)\n",
      "Trainable params: 8187489 (31.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "cnn = Sequential()\n",
    "\n",
    "# Add first convolutional layer\n",
    "cnn.add(Conv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = (3, 3),\n",
    "    activation = 'relu',\n",
    "    input_shape = (height_px, width_px, num_channels)\n",
    "))\n",
    "\n",
    "# Add first pooling layer\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add second convolutional layer\n",
    "cnn.add(Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = (3, 3),\n",
    "    activation = 'relu'\n",
    "))\n",
    "\n",
    "# Add second pooling layer\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add third convolutional layer\n",
    "cnn.add(Conv2D(\n",
    "    filters = 128,\n",
    "    kernel_size = (3, 3),\n",
    "    activation = 'relu'\n",
    "))\n",
    "\n",
    "# Add third pooling layer\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output before feeding into the fully connected layers\n",
    "cnn.add(Flatten())\n",
    "\n",
    "# Add dense layers for classification\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "cnn.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "\n",
    "# Display the summary\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d3b9fb1-bbc1-444b-8c6f-67e50f2176c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "cnn.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46a90f68-bf6a-45d9-9b02-e83c4bdbf346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 1.0811 - accuracy: 0.6732\n",
      "Epoch 2/15\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.6601 - accuracy: 0.7190\n",
      "Epoch 3/15\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.5936 - accuracy: 0.7190\n",
      "Epoch 4/15\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.6082 - accuracy: 0.7190\n",
      "Epoch 5/15\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.5955 - accuracy: 0.7190\n",
      "Epoch 6/15\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.5783 - accuracy: 0.7190\n",
      "Epoch 7/15\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.5787 - accuracy: 0.7190\n",
      "Epoch 8/15\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.5755 - accuracy: 0.7190\n",
      "Epoch 9/15\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.5617 - accuracy: 0.7255\n",
      "Epoch 10/15\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.5397 - accuracy: 0.7255\n",
      "Epoch 11/15\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.5326 - accuracy: 0.7320\n",
      "Epoch 12/15\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.5162 - accuracy: 0.7320\n",
      "Epoch 13/15\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.4719 - accuracy: 0.7386\n",
      "Epoch 14/15\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.4320 - accuracy: 0.7778\n",
      "Epoch 15/15\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.3842 - accuracy: 0.8105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a1c19c00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "cnn.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs = 15,\n",
    "    shuffle = True, # reduce risk of overfitting\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cbff7c9-8aad-4bff-b2e0-dd36b6f608f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 1.1925 - accuracy: 0.7059 - 146ms/epoch - 73ms/step\n",
      "Loss: 1.1925233602523804, Accuracy: 0.7058823704719543\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = cnn.evaluate(\n",
    "    X_test_scaled,\n",
    "    y_test,\n",
    "    verbose = 2\n",
    ")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10494d54-3d2c-487a-9d8e-5f454a6a5d92",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5227b15-08ae-4b2e-850d-2ca05755fbc8",
   "metadata": {},
   "source": [
    "__GUIDELINES__\n",
    "\n",
    "- The number of filters for convolutional layers should:\n",
    "    - Be a value to the power of 2\n",
    "    - Increase for each following layer (i.e. `32`, `64`, `128`)\n",
    "- The number of neurons for the fully connected layers should:\n",
    "    - Be a value to the power of 2\n",
    "    - Decrease for each following layer (i.e. `64`, `32`)\n",
    "- Kernel size must be an odd integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6cf7b-a002-4986-bf5e-1d330036fc1a",
   "metadata": {},
   "source": [
    "### Define the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9e5a6e5d-c6dd-48d6-90f6-3e94e302dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of convolutional layers\n",
    "min_conv_layers = 2\n",
    "max_conv_layers = 8\n",
    "\n",
    "# Initial layer filters\n",
    "min_filters = 4 # power base, 2 ** 4 = 16\n",
    "max_filters = 6\n",
    "\n",
    "# Kernel size\n",
    "min_kernel = 3\n",
    "max_kernel = 9\n",
    "\n",
    "# Convolutional layer activation functions\n",
    "activation_functions = [\n",
    "    'relu', 'leaky_relu', 'tanh',\n",
    "    'elu', 'selu', 'exponential',\n",
    "    'softmax', 'softplus'\n",
    "]\n",
    "\n",
    "# Pool size\n",
    "pool_size = (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "35c2aeed-b911-44f8-aa16-acc631c9fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise options\n",
    "\n",
    "# Convolutional layers\n",
    "options_conv_layers = create_options(min_conv_layers, max_conv_layers)\n",
    "\n",
    "# Number of filters for initial layer\n",
    "initial_filters = create_options(\n",
    "    choice = 'filters',\n",
    "    min_val = min_filters,\n",
    "    max_val = max_filters\n",
    ")\n",
    "\n",
    "# Kernel size for all layers\n",
    "option_kernel = [int(val) for val in range(min_kernel, max_kernel, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6ed50fdc-1648-481f-bea9-4894bbc2cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(hp):\n",
    "    cnn_model = Sequential()\n",
    "\n",
    "    # Choose the number of convolutional layers\n",
    "    num_conv_layers = hp.Choice(\n",
    "        'num_conv_layers',\n",
    "        values = options_conv_layers\n",
    "    )\n",
    "    \n",
    "    # Choose the number of filters for the first layer\n",
    "    initial_filters = hp.Choice(\n",
    "        'filters_layer_1',\n",
    "        values = options_initial_filters\n",
    "    )\n",
    "\n",
    "    # Choose kernel size for all convolutional layers\n",
    "    kernel_size = hp.Choice(\n",
    "        'kernel_size',\n",
    "        values = option_kernel\n",
    "    )\n",
    "\n",
    "    # Choose intial activation function\n",
    "    initial_activation = hp.Choice('conv_activation_1', activation_functions)\n",
    "\n",
    "    # Create first convolutional layer\n",
    "    cnn_model.add(Conv2D(\n",
    "        filters = initial_filters,\n",
    "        kernel_size = kernel_size,\n",
    "        activation = initial_activation,\n",
    "        input_shape = (height_px, width_px, num_channels)\n",
    "    ))\n",
    "\n",
    "    # Add a max pooling layer\n",
    "    cnn_model.add(MaxPooling2D(pool_size = pool_size))\n",
    "\n",
    "    # Add the rest of the convolutional layers\n",
    "    for i in range(2, num_conv_layers + 1):\n",
    "\n",
    "        # Choose the number of filters\n",
    "        \n",
    "    \n",
    "    print(f\"Num conv layers: {num_conv_layers}\")\n",
    "    print(f\"initial filters: {initial_filters}\")\n",
    "    print(f\"Kernel size (all): {kernel_size}\")\n",
    "    print(f\"Activation function: {initial_activation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ae207d20-3d95-40ac-8bf4-5f861e64c1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Num conv layers: 2\n",
      "initial filters: 16\n",
      "Kernel size (all): 3\n",
      "Activation function: relu\n"
     ]
    }
   ],
   "source": [
    "# Initialise the Hyperband tuner\n",
    "tuner_max_epochs = 20\n",
    "hp_iterations = 2\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_cnn_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    max_epochs = tuner_max_epochs,\n",
    "    hyperband_iterations = hp_iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603f9ff-fbac-46d0-88d7-74d5e2200c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
