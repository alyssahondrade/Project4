{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc53d1cb-4936-4c3e-8425-ca4ece487d55",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e05f8b64-7368-4f2a-978e-a6c80e788813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f106d0fd-9824-4fbe-8b50-e3ae5ac01133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/alyssahondrade/Documents/Work/Projects/Project 4/Project4\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a5e94de-2f12-4ca8-839b-ed53f62429a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../resources/audio_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Retrieve the audio files\u001b[39;00m\n\u001b[1;32m      2\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../resources/audio_files/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m audio_files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Ignore duplicates\u001b[39;00m\n\u001b[1;32m      6\u001b[0m duplicates \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoice005.wav\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoice006.wav\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoice054.wav\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoice055.wav\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../resources/audio_files'"
     ]
    }
   ],
   "source": [
    "# Retrieve the audio files\n",
    "audio_path = \"../resources/audio_files/\"\n",
    "audio_files = os.listdir(audio_path)\n",
    "\n",
    "# Ignore duplicates\n",
    "duplicates = ['voice005.wav', 'voice006.wav', 'voice054.wav', 'voice055.wav']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11fd831-c2a3-4630-be75-ce13f3d89ecd",
   "metadata": {},
   "source": [
    "## Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e766cf04-f3aa-4107-9eaf-f82ec941b954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating spectrograms: 100%|██████████████████| 209/209 [00:14<00:00, 14.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create the spectrograms\n",
    "for file in tqdm(audio_files, desc=\"Creating spectrograms\"):\n",
    "    \n",
    "    # Only read .wav files\n",
    "    if (file.endswith(\".wav\")) and (file not in duplicates):\n",
    "        \n",
    "        # Load the file\n",
    "        y, sr = librosa.load(\n",
    "            audio_path + file, # full file path\n",
    "            sr = None # preserve sampling rate\n",
    "        )\n",
    "\n",
    "        # Plot the spectrogram\n",
    "        D = librosa.amplitude_to_db(\n",
    "            np.abs(librosa.stft(y)),\n",
    "            ref = np.max\n",
    "        )\n",
    "\n",
    "        # Plot the spectrogram\n",
    "        librosa.display.specshow(\n",
    "            D,\n",
    "            sr = sr,\n",
    "            x_axis = 'time',\n",
    "            y_axis = 'linear' # can also choose: linear\n",
    "        )\n",
    "        \n",
    "        # Define the filename\n",
    "        filename = file.split(\".\")[0]\n",
    "\n",
    "        # Remove labels and border\n",
    "        plt.tight_layout()\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Export image\n",
    "        plt.savefig(\n",
    "            f'../resources/spectrograms/linear/{filename}.png',\n",
    "            bbox_inches = 'tight',\n",
    "            pad_inches = 0\n",
    "        )\n",
    "        \n",
    "        # Close the figure to avoid runtime warning\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02048bb9-3198-446e-accc-a5f1ce221807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image path and files\n",
    "image_path = \"../resources/spectrograms/linear/\"\n",
    "image_files = os.listdir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bc7081f-489a-4d04-9aae-7e3ca09b4547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing spectrograms: 100%|██████████████████| 205/205 [00:09<00:00, 20.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Resize each image\n",
    "new_width, new_height = 305, 225\n",
    "\n",
    "for image_name in tqdm(image_files, desc=\"Resizing spectrograms\"):\n",
    "    \n",
    "    # Only read .png files\n",
    "    if image_name.endswith(\".png\"):\n",
    "        \n",
    "        # Open the image file\n",
    "        img = Image.open(image_path + image_name)\n",
    "        \n",
    "        # Resize\n",
    "        resized = img.resize((new_width, new_height))\n",
    "        \n",
    "        # Create a new figure\n",
    "        plt.figure(figsize=(new_width / 100, new_height / 100))\n",
    "        \n",
    "        # Plot the resized image\n",
    "        plt.imshow(resized)\n",
    "\n",
    "        # Define the filename\n",
    "        filename = image_name.split(\".\")[0]\n",
    "        \n",
    "        # Remove labels and border\n",
    "        plt.tight_layout()\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Export image\n",
    "        plt.savefig(\n",
    "            f'../resources/spectrograms/resized/{filename}.png',\n",
    "            bbox_inches = 'tight',\n",
    "            pad_inches = 0\n",
    "        )\n",
    "        \n",
    "        # Close the figure to avoid runtime warning\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e2d755f-eaed-419c-9331-cb00f88d39b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resized image path and files\n",
    "resized_path = \"../resources/spectrograms/resized/\"\n",
    "resized_files = os.listdir(resized_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c209ee4-ad57-45e6-a8ae-ea384db37cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>format</th>\n",
       "      <th>mode</th>\n",
       "      <th>width_px</th>\n",
       "      <th>height_px</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>voice156</td>\n",
       "      <td>PNG</td>\n",
       "      <td>RGBA</td>\n",
       "      <td>225</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>voice142</td>\n",
       "      <td>PNG</td>\n",
       "      <td>RGBA</td>\n",
       "      <td>225</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>voice195</td>\n",
       "      <td>PNG</td>\n",
       "      <td>RGBA</td>\n",
       "      <td>225</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>voice181</td>\n",
       "      <td>PNG</td>\n",
       "      <td>RGBA</td>\n",
       "      <td>225</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>voice022</td>\n",
       "      <td>PNG</td>\n",
       "      <td>RGBA</td>\n",
       "      <td>225</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id format  mode  width_px  height_px\n",
       "0  voice156    PNG  RGBA       225        166\n",
       "1  voice142    PNG  RGBA       225        166\n",
       "2  voice195    PNG  RGBA       225        166\n",
       "3  voice181    PNG  RGBA       225        166\n",
       "4  voice022    PNG  RGBA       225        166"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise a list to hold the dictionaries\n",
    "spectro_list = []\n",
    "id_list = []\n",
    "r_list = []\n",
    "g_list = []\n",
    "b_list = []\n",
    "a_list = []\n",
    "\n",
    "# Loop through each image\n",
    "for resized_image in resized_files:\n",
    "    \n",
    "    # Only read .png files\n",
    "    if resized_image.endswith(\".png\"):\n",
    "        \n",
    "        # Initialise a dictionary to hold the pixels\n",
    "        spectro_dict = dict()\n",
    "\n",
    "        # Open the image file\n",
    "        img = Image.open(resized_path + resized_image)\n",
    "\n",
    "        # Convert image to array format\n",
    "        img_array = img_to_array(img)\n",
    "        \n",
    "        # Add image attributes and array to dictionary\n",
    "        spectro_dict['id'] = resized_image.split(\".\")[0]\n",
    "        spectro_dict['format'] = img.format\n",
    "        spectro_dict['mode'] = img.mode\n",
    "        spectro_dict['width_px'] = img.width\n",
    "        spectro_dict['height_px'] = img.height\n",
    "        \n",
    "        id_list.append(resized_image.split(\".\")[0])\n",
    "        r_list.append(img_array[:, :, 0].flatten().astype(int))\n",
    "        g_list.append(img_array[:, :, 1].flatten().astype(int))\n",
    "        b_list.append(img_array[:, :, 2].flatten().astype(int))\n",
    "        a_list.append(img_array[:, :, 3].flatten().astype(int))\n",
    "        \n",
    "        spectro_list.append(spectro_dict)\n",
    "\n",
    "# Create a list of RGBA lists\n",
    "rgba_list = [r_list, g_list, b_list, a_list]\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "spectro_df = pd.DataFrame(spectro_list)\n",
    "spectro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d187330d-62c5-4874-9083-c046a8684587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exporting as CSV: 4it [00:36,  9.23s/it]\n"
     ]
    }
   ],
   "source": [
    "# Colour reference list\n",
    "colours = ['r', 'g', 'b', 'a']\n",
    "\n",
    "# Loop through each file\n",
    "for idx, colour_list in tqdm(enumerate(rgba_list), desc=\"Exporting as CSV\"):\n",
    "    \n",
    "    # Create a dataframe of each colour\n",
    "    df = pd.DataFrame(colour_list)\n",
    "    \n",
    "    # Use id as the index to the dataframe\n",
    "    df.index = id_list\n",
    "    \n",
    "    # Export to CSV\n",
    "    df.transpose().to_csv(\n",
    "        f'../resources/clean_data/{colours[idx]}val.csv',\n",
    "        encoding = 'utf8',\n",
    "        index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff41c1-4bed-48ff-99d5-4db37b0505dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
