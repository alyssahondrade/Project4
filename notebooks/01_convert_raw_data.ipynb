{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29b9e4a-bfab-48d5-9ef0-d61d2962ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "import wfdb\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "979f7b47-f2ca-4436-b7e7-8e1ea10069fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "\n",
    "# Since audio data, need signed bit integer\n",
    "# According to dataset: 32-bit\n",
    "SIGNED_32BIT = 2**31 - 1\n",
    "\n",
    "# According to dataset: 8000Hz\n",
    "SAMPLING_FREQ = 8000\n",
    "\n",
    "# Since 32-bit, 8bits/byte\n",
    "SAMPLE_WIDTH = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce796cb-779f-47ec-aa7a-2351377364d9",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed59e83e-b4c8-485b-8a89-f338d04776e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info file: 208\n",
      "Signal file: 208\n",
      "Audio file: 208\n"
     ]
    }
   ],
   "source": [
    "# Raw dataset file path\n",
    "rawdata_path = \"../resources/voiced_dataset/\"\n",
    "\n",
    "# Get all the files in the directory\n",
    "files = os.listdir(rawdata_path)\n",
    "\n",
    "# Create lists to check dataset\n",
    "voice_info = []\n",
    "voice_file = []\n",
    "audio_file = []\n",
    "\n",
    "# Loop through each file\n",
    "for file in files:\n",
    "    \n",
    "    # Look through voice files only\n",
    "    if file.startswith(\"voice\"):\n",
    "        \n",
    "        # Isolate the info text files\n",
    "        if file.endswith(\"-info.txt\"):\n",
    "            voice_id = file.split(\"-\")[0]\n",
    "            voice_info.append(voice_id)\n",
    "        \n",
    "        # Isolate the voice text files\n",
    "        elif file.endswith(\".txt\"):\n",
    "            voice_id = file.split(\".\")[0]\n",
    "            voice_file.append(voice_id)\n",
    "            \n",
    "        # Isolate the audio files\n",
    "        elif file.endswith(\".hea\"):\n",
    "            voice_id = file.split(\".\")[0]\n",
    "            audio_file.append(voice_id)\n",
    "\n",
    "# Confirm each sample has a signal and info file\n",
    "print(f'Info file: {len(set(voice_info))}')\n",
    "print(f'Signal file: {len(set(voice_file))}')\n",
    "print(f'Audio file: {len(set(audio_file))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df192a-4185-4730-b053-568e504ef71b",
   "metadata": {},
   "source": [
    "## Convert wfdb to wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e501cc4c-9541-4ed7-8408-50364109e1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to wav: 100%|████████████████████| 834/834 [00:00<00:00, 6089.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert to a wav file\n",
    "for file in tqdm(files, desc=\"Converting to wav\"):\n",
    "    \n",
    "    # Extract .hea files only\n",
    "    if file.startswith(\"voice\") and file.endswith(\".hea\"):\n",
    "        voice_id = file.split(\".\")[0]\n",
    "        \n",
    "        # Get the record name\n",
    "        record_name = rawdata_path + voice_id\n",
    "        \n",
    "        # Read the wfdb record\n",
    "        record = wfdb.rdrecord(record_name)\n",
    "        \n",
    "        # Get the signal data and sampling freq (fs)\n",
    "        signal_data = record.p_signal\n",
    "        fs = record.fs\n",
    "        \n",
    "        # Find the min and max of the signal data\n",
    "        signal_min = np.min(signal_data)\n",
    "        signal_max = np.max(signal_data)\n",
    "        \n",
    "        # Normalise and scale to 32-bit range\n",
    "        normalised_signal = (signal_data - signal_min) / (signal_max - signal_min)\n",
    "        normalised_signal = (SIGNED_32BIT * normalised_signal).astype(np.int32)\n",
    "        \n",
    "        # Create an AudioSegment from the normalised signal data\n",
    "        audio_segment = AudioSegment(\n",
    "            normalised_signal.tobytes(),\n",
    "            frame_rate = fs,\n",
    "            sample_width = SAMPLE_WIDTH,\n",
    "            channels = 1 # mono, not stereo\n",
    "        )\n",
    "        \n",
    "        # Save as a wav file\n",
    "        output_filename = f'../resources/audio_files/{voice_id}.wav'\n",
    "        audio_segment.export(output_filename, format='wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
