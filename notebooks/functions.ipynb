{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d1d7a7-19c6-485b-b91f-3b70469c6911",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7df03-33e1-4948-b350-c411d1b95871",
   "metadata": {},
   "source": [
    "## Metadata Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c56aca-1669-4303-93bf-6d166f8c561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_values(str_input, delimiter):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Convert an input such as \"25-50 g\" to a single\n",
    "    integer value that is the average of the numbers\n",
    "    (37.5 in this case).\n",
    "    \n",
    "    Input:\n",
    "        str_input = the string to convert\n",
    "        delimiter = what to split the string by\n",
    "        \n",
    "    Output:\n",
    "        mean_value\n",
    "    \"\"\"\n",
    "    # Split by the delimiter\n",
    "    sep_values = str_input.split(delimiter)\n",
    "    \n",
    "    # Convert each value to an integer\n",
    "    sep_values = [int(val) for val in sep_values]\n",
    "    \n",
    "    # Calculate the mean value\n",
    "    mean_value = mean(sep_values)\n",
    "    \n",
    "    return mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a9393fa-29b3-43a5-ae5a-b8f7b88c5928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pd(value):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    - Clean numerical 'X_pd' columns.\n",
    "    - To be used with `apply()`.\n",
    "    \n",
    "    Pipeline:\n",
    "    - Convert to a string for manipulation.\n",
    "    - Strip non-numerical values.\n",
    "    - Calculate averages as required.\n",
    "    - Return an int value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Values which do not need cleaning\n",
    "    try:\n",
    "        return float(value)\n",
    "    \n",
    "    # Values which need cleaning\n",
    "    except:\n",
    "        # Convert value to a string\n",
    "        value = str(value)\n",
    "\n",
    "        ### REMOVE STRINGS ###\n",
    "        # Check if 'week' is in the value\n",
    "        if ' week' in value:\n",
    "            \n",
    "            # Variation #1: per week\n",
    "            if ' per week' in value:\n",
    "                # Remove the ' per week' string\n",
    "                converted = value.replace(\" per week\", \"\").strip()\n",
    "\n",
    "            # Variation #2: for week\n",
    "            elif ' for week' in value:\n",
    "                # Remove the ' for week' string\n",
    "                converted = value.replace(\" for week\", \"\").strip()\n",
    "            \n",
    "            # Check for a dash\n",
    "            if '/' in converted:\n",
    "                result = split_values(converted, \"/\")\n",
    "            else:\n",
    "                result = converted\n",
    "            \n",
    "            # Get the per day value\n",
    "            per_day = round(int(result)/7, 2)\n",
    "\n",
    "            return per_day\n",
    "        \n",
    "        # Check if ' for mounth' is in the value\n",
    "        elif ' for mounth' in value:\n",
    "            \n",
    "            # Remove the ' for mounth'\n",
    "            converted = value.replace(\" for mounth\", \"\")\n",
    "            \n",
    "            # Check for a dash\n",
    "            if '-' in converted:\n",
    "                result = split_values(converted, \"-\")\n",
    "            else:\n",
    "                result = converted\n",
    "            \n",
    "            # Get the per day value\n",
    "            per_day = round(float(result)/30,  2)\n",
    "            \n",
    "            return per_day\n",
    "        \n",
    "        # Check if '/ month' is in the value\n",
    "        elif '/ month' in value:\n",
    "            \n",
    "            # Convert to a list delimited by a space\n",
    "            space_list = value.split(\" \")\n",
    "            \n",
    "            # Get the per day value\n",
    "            per_day = int(space_list[0])/30\n",
    "            \n",
    "            return per_day\n",
    "        \n",
    "        # Check if 'g' is in the value:\n",
    "        elif 'g' in value:\n",
    "            \n",
    "            # Find the index of 'g'\n",
    "            g_index = value.find('g')\n",
    "            \n",
    "            # Strip the remainder and whitespace\n",
    "            converted = value[:g_index].strip()\n",
    "            \n",
    "            # Check for delimiters\n",
    "            if '-' in converted:\n",
    "                result = split_values(converted, \"-\")\n",
    "            elif '/' in converted:\n",
    "                result = split_values(converted, \"/\")\n",
    "            else:\n",
    "                result = converted\n",
    "\n",
    "            return result\n",
    "        \n",
    "        ### CALCULATE AVERAGES ###\n",
    "        elif '/' in value:\n",
    "            return split_values(value, \"/\")\n",
    "        \n",
    "        elif '-' in value:\n",
    "            return split_values(value, \"-\")\n",
    "        \n",
    "        ### OTHER CLEANING ###\n",
    "        elif ',' in value:\n",
    "            return float(value.replace(\",\", \".\"))\n",
    "        \n",
    "        # Catchall\n",
    "        else:\n",
    "            return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c55bd56-02f2-4307-ac55-786dccf148ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation(df, cat_col, num_col):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Check whether the missing data should be\n",
    "    imputed with a mean or a median.\n",
    "    \n",
    "    If the absolute skew score > 0.5, MEDIAN.\n",
    "    Else, not skewed, MEAN.\n",
    "    \n",
    "    Input:\n",
    "    df = dataframe\n",
    "    cat_col = categorical column\n",
    "    num_col = numerical column\n",
    "        \n",
    "    Output:\n",
    "        histogram\n",
    "        skewness score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the unique values from the categorical column\n",
    "    unique_values = df[cat_col].unique()\n",
    "    print(unique_values)\n",
    "    \n",
    "    # Loop through each unique value\n",
    "    for unique in unique_values:\n",
    "        \n",
    "        # If the value is 'never', set the value to `0`\n",
    "        df.loc[df[cat_col] == 'never', num_col] = 0\n",
    "        \n",
    "        # Get the non-null values per unique\n",
    "        check_condition = (df[cat_col] == unique) & (~df[num_col].isnull())\n",
    "        check_data = df.loc[check_condition, num_col]\n",
    "        \n",
    "        # Check for unique values with 'nan' values\n",
    "        check_null = df.loc[df[cat_col] == unique, num_col].value_counts(dropna=False).index\n",
    "        \n",
    "        # Skip if all values valid\n",
    "        if (np.nan not in check_null) or (len(check_data) == 0):\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            # Convert values for plotting\n",
    "            check_data = check_data.astype(float)\n",
    "            \n",
    "            # Histogram\n",
    "            check_data.hist()\n",
    "            \n",
    "            # Clean title\n",
    "            title = cat_col.replace(\"_\", \" \").title()\n",
    "            plt.title(f'{title} ({unique})')\n",
    "            plt.xlabel(f'{title} per Day')\n",
    "            plt.ylabel('Frequency')\n",
    "            \n",
    "            # Calculate the skewness\n",
    "            skew_score = skew(check_data)\n",
    "            \n",
    "            # Display the results\n",
    "            plt.show()\n",
    "            \n",
    "            # Check the skew score\n",
    "            if abs(skew_score) > 0.5: # skewed = use median\n",
    "                chosen_value = df.loc[check_condition, num_col].astype(float).median()\n",
    "                print(f'Skewness: {round(skew_score,2)}, use MEDIAN.')\n",
    "                print(f'Median value for \"{unique}\": {round(chosen_value, 2)}')\n",
    "            \n",
    "            else:\n",
    "                chosen_value = df.loc[check_condition, num_col].astype(float).mean()\n",
    "                print(f'Skewness: {round(skew_score,2)}, use MEAN.')\n",
    "                print(f'Mean value for \"{unique}\": {round(chosen_value, 2)}')\n",
    "            \n",
    "            # Round the chosen value\n",
    "            rounded_value = round(chosen_value, 2)\n",
    "            \n",
    "            # Impute the missing values\n",
    "            null_condition = (df[cat_col] == unique) & (df[num_col].isnull())\n",
    "            df.loc[null_condition, num_col] = rounded_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e26841f-88a4-4ce0-81d1-70e0fac7c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fruit_gram(value):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    - Convert gram-value to number of fruits.\n",
    "    - To be used with `apply()`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define a standard serve\n",
    "    std_serve = 150\n",
    "    \n",
    "    # Values which do not need cleaning\n",
    "    try:\n",
    "        # Look for values greater than 5\n",
    "        if float(value) > 5:\n",
    "\n",
    "            # Convert to number of fruits\n",
    "            num_fruits = round(int(value)/std_serve, 2)\n",
    "\n",
    "            return num_fruits\n",
    "        \n",
    "        # Catchall\n",
    "        else:\n",
    "            return float(value)\n",
    "    \n",
    "    except:\n",
    "        # Look for 'gramme'\n",
    "        if ' gramme' in value:\n",
    "            converted = value.replace(\" gramme\", \"\").strip()\n",
    "\n",
    "            # Convert to number of fruits\n",
    "            num_fruits = round(int(converted)/std_serve, 2)\n",
    "\n",
    "            return num_fruits\n",
    "\n",
    "        # Catchall\n",
    "        else:\n",
    "            return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bf0d4b-2a20-4b4a-a64e-5946a82b3785",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e32472-eaae-4c4b-a868-2e0d1be1e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_unique(df, max_value, columns_to_limit):\n",
    "    \"\"\"\n",
    "    Purpose of the function is to limit the number of unique values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loop through each column\n",
    "    for col in columns_to_limit:\n",
    "        # Get the value counts of the column\n",
    "        total_counts = df[col].value_counts()\n",
    "        \n",
    "        # Get the top values to retain, not including \"Other\"\n",
    "        top_counts = total_counts[:max_value-1]\n",
    "        \n",
    "        # Define the cutoff\n",
    "        cutoff_value = top_counts.iloc[-1]\n",
    "        \n",
    "        # Create a list of values to replace\n",
    "        replace_values = total_counts.loc[total_counts.values < cutoff_value].index\n",
    "        \n",
    "        # Replace in dataframe\n",
    "        for value in replace_values:\n",
    "            df[col] = df[col].replace(value, \"other\")\n",
    "        \n",
    "        # Check to make sure binning was successful\n",
    "        print(df[col].value_counts())\n",
    "        print(f'Number of unique values: {df[col].nunique()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b66b7f80-8cf7-4834-9ad0-4dfe66cea621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_binary(value):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    - Encode 'healthy' to '0'\n",
    "    - All other options to '1'\n",
    "    \"\"\"\n",
    "    \n",
    "    if value == 'healthy':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88cd42e2-1ad5-412b-819e-e28435e82568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "    \n",
    "    # Choose activation function in hidden layers\n",
    "    activation_first_hidden = hp.Choice('activation_layer_0', activation_functions)\n",
    "    \n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(\n",
    "        units = hp.Int(\n",
    "            'units_layer_0',\n",
    "            min_value = 1,\n",
    "            max_value = max_num_neurons,\n",
    "            step = step_count),\n",
    "        activation = activation_first_hidden,\n",
    "        # kernel_regularizer = tf.keras.regularizers.L1(0.01),\n",
    "        input_dim = number_input_features\n",
    "    ))\n",
    "    \n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    num_layers = hp.Int('num_layers', 1, max_hidden_layers-1) # options: 1, 2\n",
    "    \n",
    "    for i in range(1, num_layers+1): # i-values: 1, 2 only\n",
    "        # Choose the number of neurons per layer\n",
    "        units_layer_i = hp.Int(\n",
    "            f'units_layer_{i}',\n",
    "            min_value = 1,\n",
    "            max_value = max_num_neurons,\n",
    "            step = step_count\n",
    "        )\n",
    "        \n",
    "        # Choose a different activation function for each layer\n",
    "        activation_layer_i = hp.Choice(f'activation_layer_{i}', activation_functions)\n",
    "\n",
    "        nn_model.add(tf.keras.layers.Dense(\n",
    "            units = units_layer_i,\n",
    "            activation = activation_layer_i,\n",
    "            # kernel_regularizer = tf.keras.regularizers.L1(0.01)\n",
    "        ))\n",
    "\n",
    "    # Add the output layer\n",
    "    nn_model.add(tf.keras.layers.Dense(\n",
    "        units = 1,\n",
    "        activation = \"sigmoid\"\n",
    "    ))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(\n",
    "        loss = \"binary_crossentropy\",\n",
    "        optimizer = \"adam\",\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return(nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea97c51-2107-4525-bc2d-a25018becbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_power_of_two(x):\n",
    "    # Ensure number of filters uses powers of 2\n",
    "    return 2 ** math.ceil(math.log2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf1cdbf-7ba1-4db1-8e7a-62874fe96811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(hp):\n",
    "    cnn_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27e503c1-d5a0-4ba6-a0bb-611661b532c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(hp):\n",
    "    cnn_model = Sequential()\n",
    "    \n",
    "    powers_of_two_filters = [2**i for i in range(1, 9)]\n",
    "    print(powers_of_two_filters)\n",
    "    \n",
    "    # Choose the number of convolutional layers\n",
    "    num_conv_layers = hp.Int(\n",
    "        'num_conv_layers',\n",
    "        min_value = 1,\n",
    "        max_value = max_conv_layers\n",
    "    )\n",
    "    print(num_conv_layers)\n",
    "    \n",
    "    for i in range(1, num_conv_layers+1):\n",
    "        \n",
    "        # Choose the number of filters for each convolutional layer\n",
    "        # filters = hp.Choice(\n",
    "        #     f'conv_filters_{i}',\n",
    "        #     values = [\n",
    "        #         next_power_of_two(2 * prev_filter),\n",
    "        #         next_power_of_two(4 * prev_filter)\n",
    "        #     ]\n",
    "        # )\n",
    "        filters = hp.Choice(\n",
    "            f'filters_layer_{i}',\n",
    "            values = powers_of_two_filters)\n",
    "        \n",
    "        # Choose the kernel size for each convolutional layer\n",
    "        kernel_size = hp.Choice(\n",
    "            f'conv_kernel_size_{i}',\n",
    "            values = kernel_choice\n",
    "        )\n",
    "        \n",
    "        # Choose the activation function for each convolutional layer\n",
    "        activation = hp.Choice(\n",
    "            f'conv_activation_{i}',\n",
    "            activation_functions\n",
    "        )\n",
    "        \n",
    "        # Add the convolutional layer\n",
    "        cnn_model.add(Conv2D(\n",
    "            filters = filters,\n",
    "            kernel_size = (kernel_size, kernel_size),\n",
    "            activation = activation,\n",
    "            input_shape = (height_px, width_px, num_channels) if i == 1 else None\n",
    "        ))\n",
    "        \n",
    "        # Add a max pooling layer after each convolutional layer\n",
    "        cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "    # Flatten the output before passing it to dense layers\n",
    "    cnn_model.add(Flatten())\n",
    "\n",
    "    # Choose the number of dense layers\n",
    "    num_dense_layers = hp.Int(\n",
    "        'num_dense_layers',\n",
    "        min_value = 1,\n",
    "        max_value = max_dense_layers\n",
    "    )\n",
    "    \n",
    "    for i in range(1, num_dense_layers+1):\n",
    "        \n",
    "        # Choose the activation function for each dense layer\n",
    "        activation = hp.Choice(\n",
    "            f'dense_activation_{i}',\n",
    "            activation_functions\n",
    "        )\n",
    "        \n",
    "#         if (i == 1):\n",
    "#             # First dense layer\n",
    "#             units_first_dense = hp.Int(\n",
    "#                 'dense_units_1',\n",
    "#                 min_value = min_dense_neurons,\n",
    "#                 max_value = max_dense_neurons,\n",
    "#                 step = min_dense_neurons\n",
    "#             )\n",
    "            \n",
    "#             cnn_model.add(Dense(\n",
    "#                 units = units_first_dense,\n",
    "#                 activation = activation\n",
    "#             ))\n",
    "        \n",
    "        # Define the max neurons based on previous layer\n",
    "        # max_neurons = next_power_of_two(model.layers[-1].output_shape[1])\n",
    "        \n",
    "        # Stop adding layers if <= 0\n",
    "        # if max_neurons <= 0:\n",
    "            # break\n",
    "            \n",
    "        # Choose the number of units for each dense layer\n",
    "        units = hp.Int(\n",
    "            f'dense_units_{i}',\n",
    "            min_value = min_dense_neurons,\n",
    "            max_value = max_dense_neurons,\n",
    "            step = min_dense_neurons\n",
    "        )\n",
    "\n",
    "        # Add the dense layer\n",
    "        cnn_model.add(Dense(\n",
    "            units = units,\n",
    "            activation = activation\n",
    "        ))\n",
    "\n",
    "    # Add the output layer\n",
    "    cnn_model.add(Dense(\n",
    "        units = 1,\n",
    "        activation = \"sigmoid\"\n",
    "    ))\n",
    "\n",
    "    # Compile the model\n",
    "    cnn_model.compile(\n",
    "        loss = \"binary_crossentropy\",\n",
    "        optimizer = \"adam\",\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return(cnn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5f48b-e88e-40f9-bd94-8a16506c18bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
